{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmxKmB0A4M4cW+N0+nGamB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "\n",
        "For working with neural networks, we require a dedicated library due to a number of reasons:\n",
        "\n",
        "- Abstraction for the NN implementation\n",
        "- Proper Support for Autograd (for backpropagation)\n",
        "- Support for different optimizers and other auxiliary NN techniques, etc.\n",
        "\n",
        "Luckily, PyTorch provides plenty of these features. Actually, PyTorch is based on the classical Torch library implemented in Lua (used to be popular before Tensorflow came in 2015).\n",
        "\n",
        "We can simply import it as:"
      ],
      "metadata": {
        "id": "F3ozdf7VusmV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lirmW9uMm0Uo"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "Similar to NumPy's arrays or JAX's NumPy arrays, PyTorch's building blocks are tensors. A tensor is nothing but a generalization of a matrix in higher dimensions.\n",
        "\n",
        "Similar to JAX's arrays, PyTorch tensors can also run on the GPUs, making them the ultimate choice for Deep Learning."
      ],
      "metadata": {
        "id": "ALCh-SqWwNiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation from Python Collections\n",
        "\n",
        "We can initialize a tensor as:\n",
        "\n",
        "`<tensor> = torch.tensor(<collection>)`\n",
        "\n",
        "Lets try it. I am as anxious as you."
      ],
      "metadata": {
        "id": "2rlgFKmsycGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listA = [1, 2, 3]\n",
        "setB = {2,4,6}\n",
        "tupleC = (1,3,5)"
      ],
      "metadata": {
        "id": "NtXh8xk-22_m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorA = torch.tensor(listA)\n",
        "tensorA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLWODu5x2_bu",
        "outputId": "ad439c5b-7d7b-4786-f27e-d37ab5e59c83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its type would be:"
      ],
      "metadata": {
        "id": "eUmbj7Pw3Enz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(tensorA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwEVEZxk3MJQ",
        "outputId": "eb9d73a0-4852-4740-9f76-0da816f1194f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch doesn't work with sets as well (as we saw for the JAX)."
      ],
      "metadata": {
        "id": "qbHcVP1J4vHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorB = torch.tensor(setB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "8fp5V94L4gTT",
        "outputId": "a866bf03-0a71-454c-a2dc-3373173f15b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-52162d4385ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtensorC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtupleC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of set"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorC = torch.tensor(tupleC)\n",
        "tensorC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIqOui_C41Vx",
        "outputId": "1fb62671-f5c9-4e9a-a800-f58593fb6e80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From NumPy Arrays\n",
        "\n",
        "Similarly, we can also make them using the (more useful, versatile) NumPy arrays."
      ],
      "metadata": {
        "id": "Ot9As9DR31tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "npA = np.arange(1,10)\n",
        "\n",
        "tensorD = torch.tensor(npA)\n",
        "tensorD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OvvDbNg5mO_",
        "outputId": "12331b26-5bca-4755-dc36-08d87b1ddb84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there any difference in the type? No!"
      ],
      "metadata": {
        "id": "-vILPfO76nHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(tensorD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZQNXqYf6p7t",
        "outputId": "591b276c-53d8-4eac-d556-0110a4526cd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intrinsic Creation\n",
        "\n",
        "Just like we saw how we can initialize NumPy (or JAX) arrays from the scratch with some built-in functions, we can do the same for the tensors as well.\n",
        "\n",
        "Like:\n",
        "\n",
        "- `ones()`\n",
        "- `zeros()`\n",
        "\n",
        "**Note:** They take `<shape>` as the argument."
      ],
      "metadata": {
        "id": "D4Uwm-a36uQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorE = torch.ones((3,3))\n",
        "tensorE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwA5jjV0A6hJ",
        "outputId": "f3bc2924-dada-41b4-ac39-5244362b0d05"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorF = torch.zeros((3,4))\n",
        "tensorF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNsdt55mBKbL",
        "outputId": "7b355724-b933-438b-b4b8-e80727920aab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** If you feel comfortable with NumPy arrays, you can always make an intrinsic NumPy array and convert it into a tensor."
      ],
      "metadata": {
        "id": "CLAhPfrDBTay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attributes\n",
        "\n",
        "We saw above that `type()` of all tensors is same. Though, similar to the JAX arrays, they can have different datatype (`dtype`).\n",
        "\n",
        "We have following common attributes for a tensor:\n",
        "\n",
        "- `dtype`\n",
        "- `shape`\n",
        "- `device` – CPU or GPU"
      ],
      "metadata": {
        "id": "r-LC9ip6EF-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorF.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-watFssaEiXS",
        "outputId": "56d2e14e-370b-4edd-b976-cc80e1a633ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorF.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKZudy01EyJC",
        "outputId": "e61851f8-a33c-4254-f899-02fbe8e55aa2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** It doesn't work on JAX arrays yet. Things may change in the future with Keras 3.0. Can verify it by uncommenting the cell below."
      ],
      "metadata": {
        "id": "gew8JmX05MWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "jnpA = jnp.array(listA)\n",
        "tensorD = torch.tensor(jnpA) #Uncomment it to check the error\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsaD75O3465J",
        "outputId": "95f16b63-3e6f-4eba-d727-5ed90a8393c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([1, 2, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Broadcasting\n",
        "\n",
        "Broadcasting is one of the confusing aspect of Numerical computing being inconsistent with the Linear Algebra."
      ],
      "metadata": {
        "id": "OZDPAoEhFUsd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qvd7rcjlwuRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoDiff\n",
        "\n",
        "Similar to JAX, PyTorch also has a strong auto-differentiation unit.\n",
        "\n",
        "--To Be COntinued---"
      ],
      "metadata": {
        "id": "0cAaOHmWwu07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommended Resources\n",
        "\n",
        "- [Microsoft Learn – PyTorch Fundamentals](https://learn.microsoft.com/en-us/training/paths/pytorch-fundamentals/)"
      ],
      "metadata": {
        "id": "DnQEgnlAxNJ9"
      }
    }
  ]
}